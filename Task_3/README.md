__**Волчкова Дарья Алексеевна  УИБО-13-24**__
__________________________________________________________
# <p align="center">Алгоритмы сортировки</p>

## Сортировка выбором (Selection Sort)
* **Определение:** на каждом шаге алгоритма находят минимальный элемент среди последних и меняют его местами с текущим элементом в массиве
* **Анализ алгоритма:**
    * Выбор минимального элемента: На каждом этапе ищется минимальный элемент из всех последующих позиций массива (int minIndex = i;)
    * Замена местоположением: Минимальный элемент меняется местами с текущим элементом, обеспечивая постепенное формирование отсортированного начала массива (arr[i] = arr[minIndex];)
    * Повторение процесса: Эта процедура повторяется для каждого элемента, пока весь массив не будет отсортирован (for (int i = 0; i < n - 1; ++i))
* **Временная сложность:** O(n²)
* **Объяснение временной сложности:**
    * Временная сложность O(n²) возникает из-за двух вложенных циклов, где внешний цикл выполняется n раз, а внутренний в среднем проходит n/2 элементов.
    * Общее количество операций составляет примерно n × n/2 = n²/2, что соответствует O(n²).
    * Каждая итерация включает поиск минимума в неотсортированной части массива, что требует линейного времени. Суммарно это дает квадратичную зависимость времени выполнения от размера массива.



__________________________________________________________
## Сортировка обменом (пузырьком) (Bubble Sort)
* **Определение:** алгоритм проходит по списку несколько раз, сравнивая соседние элементы и меняя их местами, если они находятся в неправильном порядке. Процесс повторяется до тех пор, пока список полностью не отсортируется.
* **Анализ алгоритма:**
    * Проход по массиву: последовательное сравнение соседних элементов слева направо (for i in range(n-1))
    * Сравнение и обмен: если левый элемент больше правого – выполняется обмен (if arr[j] > arr[j+1])
    * Всплытие максимумов: за каждую итерацию наибольший элемент перемещается в конец массива (arr[j], arr[j+1] = arr[j+1], arr[j])
    * Уменьшение области: с каждой итерацией обрабатывается меньшая часть массива (for j in range(n-i-1))
    * Завершение: процесс повторяется до полной сортировки массива
* **Временная сложность:** O(n²)
* **Объяснение временной сложности:**
    * Сложность O(n²) возникает из-за двух вложенных циклов, где внешний выполняется n раз, а внутренний в среднем n/2 раз, что даёт n×(n-1)/2 операций сравнения и обмена. Это приводит к квадратичной зависимости - при увеличении размера массива в k раз время выполнения возрастает в k² раз.      


__________________________________________________________
## Сортировка вставками (Insertion Sort)
* **Определение:** алгоритм строит отсортированную часть списка, постепенно вставляя каждый элемент на своё место. Он начинает с первого элемента и перемещается вправо, сравнивая каждый элемент с предыдущими элементами и вставляя его на правильное место.
* **Анализ алгоритма:**
   * Обработка n-1 элементов: последовательная обработка каждого элемента с индексами от 1 до n-1 (for i in range(1, n))
   * Поиск позиции: сравнение текущего элемента с предыдущими в отсортированной части (до 0) (while j >= 0 and arr[j] > key)
   * Сдвиг элементов: сдвиг всех элементов > key на 1 позицию вправо (до i сдвигов) (arr[j + 1] = arr[j])
   * Вставка: помещение элемента на найденную позицию j+1 после сдвига (arr[j + 1] = key)
* **Временная сложность:** O(n²)
* **Объяснение временной сложности:**
   * O(n²) возникает из-за вложенных циклов: внешний цикл for выполняется n-1 раз, а внутренний while может выполняться до i итераций для каждого элемента. Суммарно это дает 1 + 2 + 3 + ... + (n-1) = n(n-1)/2 операций, что соответствует O(n²).
   * В худшем случае (отсортированный массив в обратном порядке) каждый новый элемент приходится сравнивать со всеми предыдущими, что и приводит к квадратичной сложности.

__________________________________________________________
## Сортировка слиянием (Merge Sort)
* **Определение:** алгоритм состоит в разделении массива пополам, сортировке половин и их слиянии.
* **Анализ алгоритма:**
    * Разбиение массива: Массив рекурсивно делится пополам до тех пор, пока каждая часть не станет содержать всего один элемент (mergeSort(left);)
    * Базовый случай: Одинарные элементы рассматриваются как уже отсортированные (if (arr.length <= 1) return;)
    * Слияние частей: Отсортированные части объединяются таким образом, чтобы результирующий массив оставался отсортированным (merge(arr, left, right);)
    * Рекурсия и объединение: Эти этапы выполняются до тех пор, пока весь массив снова не соберётся вместе в отсортированном виде (quickSort(arr, low, pi - 1);)
* **Временная сложность:** O(n log n)
* **Объяснение временной сложности:**
    * Сложность O(n log n) возникает из-за логарифмического количества уровней рекурсии (log n), на каждом из которых выполняется линейное слияние (O(n)).
    * Массив последовательно делится пополам, создавая дерево рекурсии глубиной log n, а операция слияния на каждом уровне требует пропорционально n операций. Перемножение этих составляющих n × log n и дает итоговую сложность.


__________________________________________________________
## Сортировка Шелла (Shellsort)
* **Определение:** является модификацией сортировки вставками, сортирует между собой элементы, стоящие на местах, кратных определённому шагу.
* **Анализ алгоритма:**
    * Устанавливает: начальный промежуток (gap), постепенно уменьшающийся (gap = n // 2)
    * Частично сортирует элементы: находящиеся на расстоянии gap (for i in range(gap, n))
    * Завершается: обычной сортировкой вставками при gap = 1
* **Временная сложность:** O(n log² n)
* **Объяснение временной сложности:**
    * Сложность O(n log² n) возникает из-за логарифмического количества проходов (log n) с уменьшающимся промежутком, на каждом из которых выполняется модифицированная сортировка вставками. Поскольку каждый проход частично упорядочивает массив, последующие проходы требуют меньше операций, что в сумме дает O(n log² n).
    * Для последовательности промежутков n/2, n/4... сложность составляет O(n log² n), тогда как для оптимальных последовательностей можно достичь O(n log n).

__________________________________________________________
## Быстрая сортировка (Quick Sort)
* **Определение:** один из самых известных и широко используемых алгоритмов сортировки. Алгоритм состоит в выборе опорного элемента, разделении массива на две части относительно опорного (одна — все элементы, меньшие опорного элемента, вторая — большие), и в сортировке полученных частей рекурсивным вызовом себя от них
* **Анализ алгоритма:**
   * Выбор опорного элемента: выбор одного из n элементов массива в качестве разделителя (int pivot = arr[high];)
   * Разделение на подмассивы: создание двух частей - с элементами меньше и больше разделителя (if (arr[j] <= pivot))
   * Рекурсивная обработка: повторение алгоритма для обеих частей до их полной сортировки (quickSort(arr, low, pi - 1);)
   * Базовый случай: массивы из 0 или 1 элемента считаются отсортированными
* **Временная сложность:** O(n²)
* **Объяснение временной сложности:**
   * O(n²) возникает при постоянном выборе минимального или максимального элемента в качестве опорного, что приводит к максимально несбалансированному разбиению на подмассивы размером n-1 и 0. В этом случае глубина рекурсии достигает n уровней, и на каждом уровне выполняется операция разделения с линейной сложностью O(n), что в сумме дает квадратичную зависимость n + (n-1) + ... + 1 = O(n²).


__________________________________________________________
## Пирамидальная сортировка
* **Определение:** алгоритм строит кучу из исходного списка, затем постепенно извлекает наибольший элемент из кучи и помещает его в конец списка.
* **Анализ алгоритма:**
    * Создание Max-Heap: Преобразуем массив в двоичную пирамиду (max-heap), где родительские узлы всегда больше детей (for (int i = n / 2 - 1; i >= 0; i--))
    * Удаление корней: Удаляем корень (самый большой элемент) и добавляем его в конец массива, после чего повторно формируем пирамиду (arr[0] = arr[i];)
    * Повторение: Повторяем второй пункт, пока все элементы не перейдут в отсортированное состояние
* **Временная сложность:** O(n log n)
* **Объяснение временной сложности:**
    * O(n log n), поскольку операция heapify выполняется за логарифмическое время O(log n) для каждого из n элементов. Построение начальной кучи требует O(n) операций, но основное время занимает многократное извлечение элементов с восстановлением свойств кучи. Таким образом, общая сложность составляет O(n) + O(n log n) = O(n log n).

<br>
<br>
<br>

# <p align="center">Алгоритмы поиска</p>


## Последовательный (линейный) поиск
* **Определение:** простейший алгоритм поиска, осуществляемый путем последовательного сравнения каждого элемента с искомым значением до их совпадения. Временная сложность составляет O(n), что делает метод неэффективным для больших данных, однако он прост в реализации и применим для небольших или неотсортированных наборов.
* **Анализ алгоритма:**
    * Последовательный просмотр: Алгоритм последовательно просматривает элементы массива, начиная с первого (for index, element in enumerate(arr))
    * Проверка совпадения: Каждый элемент сравнивается с искомым значением (if element == target)
    * Возврат результата: Если элемент найден, возвращается его индекс; иначе возвращаем специальный маркер (-1), означающий отсутствие элемента (return index)
* **Временная сложность:** O(n)
* **Объяснение временной сложности:**
    * O(n) возникает потому, что алгоритм в худшем случае проверяет все n элементов массива. Каждый элемент сравнивается с искомым значением за постоянное время O(1), поэтому общее время работы пропорционально размеру массива. Таким образом, сложность линейного поиска всегда O(n) в худшем случае.

__________________________________________________________
## Бинарный (двоичный, дихотомический) поиск
* **Определение:** алгоритм поиска на упорядоченном множестве путём многократного деления его на две части, в одной из которых должен находиться искомый элемент. Поиск завершается при нахождении элемента или проверке всех частей. Преимущество — низкая трудоёмкость (O(log n)), недостаток — требование отсортированности данных.
* **Анализ алгоритма:**
    * Начальная установка границ: Устанавливаем левую границу (left) равной началу массива, а правую (right) — концу массива (int left = 0;)
    * Нахождение середины: Рассчитываем индекс центрального элемента массива (mid), используя формулу (left + right) / 2.
    * Сравнение: Сравниваем центральный элемент (arr[mid]) с искомым значением (target):
         - Если центральное значение равно цели, возвращаем его индекс.
         - Если оно больше цели, обновляем правую границу (right = mid - 1), сужая область поиска влево.
         - Если оно меньше цели, обновляем левую границу (left = mid + 1), смещая область поиска вправо.
    * Продолжение поиска: Повторяем процесс, пока границы не пересекутся (left > right), если цель не была найдена, возвращаем индикатор неудачи (-1)
* **Временная сложность**: O(log n)
* **Объяснение временной сложности:**
    * Сложность O(log n) возникает из-за деления массива пополам на каждом шаге. После каждой итерации область поиска сокращается в два раза, поэтому для массива из n элементов требуется не более log₂n операций. Это обеспечивает логарифмическую зависимость времени выполнения от размера массива.

__________________________________________________________
## Интерполирующий поиск
* **Определение:** это алгоритм поиска для отсортированных наборов данных, таких как массивы или списки. Он предсказывает позицию нужного элемента на основе разницы значений. Эффективен, если элементы распределены достаточно равномерно.
* **Анализ алгоритма:**
    * Вычисление позиции: Используется формула интерполяции для оценки возможной позиции искомого элемента (int pos = lo + ((double)(hi-lo)/(arr[hi]-arr[lo])*(x-arr[lo]));)
    * Сравнение: Находится ближайший элемент и сравнивается с целью (if (arr[pos] == x) return pos)
    * Рекурсия: Если элемент не найден сразу, выполняется рекурсивный поиск либо в левой, либо в правой части массива (return interpolationSearch(arr, pos + 1, hi, x);)
    * Возвращение результата: Если элемент найден, возвращается его индекс, иначе — сигнализируется ошибка (-1).
* **Временная сложность:** O(log log n)
* **Объяснение временной сложности:**
    * O(log log n) возникает благодаря интерполяционной формуле, которая предсказывает позицию элемента и обеспечивает экспоненциальное сокращение области поиска на каждом шаге.
    * При равномерном распределении данных алгоритм быстро сходится к искомому элементу, уменьшая пространство поиска гораздо быстрее, чем бинарный поиск, что приводит к двойной логарифмической сложности O(log log n) в среднем случае.

__________________________________________________________
## Поиск по Фибоначчи
* **Определение:** это эффективный алгоритм поиска, используемый для нахождения целевого значения в отсортированной коллекции, такой как массив или список. По принципу он аналогичен бинарному поиску, но использует числа Фибоначчи для определения позиций для сравнения.
* **Анализ алгоритма:**
   * Подготовка: нахождение ближайшего числа Фибоначчи Fₖ ≥ n
   * Расчёт границ: определение индексов через числа Фибоначчи Fₖ₋₁, Fₖ₋₂ (i = min(offset + fib_m2, len(arr)-1))
   * Сравнение: 
     - элемент < цели → смещение вправо (Fₖ₋₂)
     - элемент > цели → смещение влево (Fₖ₋₁)
   * Сужение области: после каждой проверки окно поиска уменьшается (fib_m = fib_m2)
   * Завершение: процесс продолжается пока Fₖ > 1 или элемент не найден
* **Временная сложность:** O(log n)
* **Объяснение временной сложности:**
  * O(log n) возникает из-за деления массива с помощью чисел Фибоначчи, которые растут экспоненциально. На каждом шаге алгоритм сокращает область поиска в отношении золотого сечения, что требует O(log n) итераций для нахождения элемента. Каждая итерация выполняется за O(1), что в сумме дает логарифмическую сложность.

